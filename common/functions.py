# ==========================================
# 1. 阶跃函数：单值版本（已弃用，仅作对比）
# ==========================================
def step_function0(x):
    if x > 0:
        return 1
    else:
        return 0

# ==========================================
# 2. 阶跃函数：支持 NumPy 数组的向量化版本
# ==========================================
import numpy as np

def step_function(x):
    # x > 0 得到布尔数组，astype(int) 转成 0/1
    return np.array(x > 0, dtype=int)

# ==========================================
# 3. Sigmoid 激活函数
# ==========================================
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# ==========================================
# 4. ReLU 激活函数
# ==========================================
def relu(x):
    return np.maximum(0, x)

# ==========================================
# 5. Softmax 函数：单值/一维数组版本（未做溢出保护）
# ==========================================
def softmax0(x):
    return np.exp(x) / np.sum(np.exp(x))

# ==========================================
# 6. Softmax 函数：通用版本（支持二维批量样本 + 溢出保护）
# ==========================================
def softmax(x):
    # -----------------
    # 二维矩阵：每行是一个样本
    # -----------------
    if x.ndim == 2:
        x = x.T                       # 先转置，方便按列计算
        x = x - np.max(x, axis=0)     # 溢出保护：每列减最大值
        y = np.exp(x) / np.sum(np.exp(x), axis=0)
        return y.T                    # 转置回来，形状与输入一致

    # -----------------
    # 一维数组：直接计算
    # -----------------
    x = x - np.max(x)                 # 溢出保护
    return np.exp(x) / np.sum(np.exp(x))

# ==========================================
# 7. 恒等函数（用于回归输出层）
# ==========================================
def identity(x):
    return x

# ==========================================
# 8. 均方误差损失（MSE）
# ==========================================
def mean_squared_error(y, t):
    return 0.5 * np.sum((y - t) ** 2)


# ==========================================
# 9. 交叉熵误差（支持顺序标签或 one-hot 标签）   模型对该类别的预测概率越高，损失越小 n 概率本身0，1之间
# ==========================================
def cross_entropy(y, t):
    # 如果是一维样本，先转成二维（1 × N）  这里都是二维这是首要的
    # 处理单个样本的情况：确保输入总是二维数组，便于统一处理
    # 例如：y.shape = (10,) → (1, 10)，t.shape = (,) → (1,)
    if y.ndim == 1:
        t = t.reshape(1, t.size)  # 将真实标签t重塑为1行n列，n为标签数量
        y = y.reshape(1, y.size)  # 将预测概率y重塑为1行n列，n为类别数量

    # 若 t 是 one-hot 编码格式，转成顺序类别标签
    # 判断条件：t的元素总数等于y的元素总数，说明t是one-hot编码
    # 例如：t.shape = (batch_size, num_classes)，y.shape = (batch_size, num_classes)
    if t.size == y.size:
        # 将one-hot编码转换为类别索引
        # 例如：[[0,0,1], [1,0,0]] → [2, 0]
        t = t.argmax(axis=1)  # 沿类别维度取最大值索引，得到每个样本的真实类别编号  这是列方向

    n = y.shape[0]  # 获取batch大小，即样本数量
    # y.shape[0]表示第0维的大小，即行数（样本数）
    # 例如：y.shape = (32, 10) → n = 32

    return -np.sum(np.log(y[np.arange(n), t] + 1e-10)) / n  #这等于是一个二类索引



# ==========================================
# 10. 简单测试
# ==========================================
if __name__ == '__main__':
    x = np.array([0, 1, 2, 3, 4, 5, -1, -2, -3, -4, -5])
    print('阶跃函数结果:', step_function(x))
    print('Sigmoid 结果 :', sigmoid(x))
    print('Tanh 结果    :', np.tanh(x))
    print('ReLU 结果    :', relu(x))

    # 二维批量样本测试 Softmax
    X = np.array([[0, 1, 2],
                  [3, 4, 5],
                  [6, 7, 8],
                  [-1, -2, -3]])
    print('Softmax 结果 :\n', softmax(X))